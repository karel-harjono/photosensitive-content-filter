{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1070bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e48259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_video(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "\n",
    "    timestamp = 0\n",
    "    mean_intensity = []\n",
    "    # Read until video is completed\n",
    "    while(cap.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            blue = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            mean_intensity.append(cv2.mean(blue)[2]) # blue is the third dimension so take the first element\n",
    "            # Display the resulting frame\n",
    "            # cv2.imshow('Frame',frame)\n",
    "\n",
    "            # Press Q on keyboard to  exit\n",
    "            # if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            #   break\n",
    "            timestamp = timestamp + 1\n",
    "        # Break the loop\n",
    "        else: \n",
    "            break\n",
    "    metadata = {\n",
    "        'frame_count': cap.get(cv2.CAP_PROP_FRAME_COUNT),\n",
    "        'fps': cap.get(cv2.CAP_PROP_FPS),\n",
    "        'frame_width': cap.get(cv2.CAP_PROP_FRAME_WIDTH),   # float `width`\n",
    "        'frame_height': cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "    }\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return [range(1, timestamp+1), mean_intensity, metadata,blue]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b05f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, metadata,blue = analyze_video('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787cf99f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## flashes tuning method\u001b[39;00m\n\u001b[0;32m      2\u001b[0m diff \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     diff\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(y[i] \u001b[38;5;241m-\u001b[39m y[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# TODO: figure out tuning metrics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m diff\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "## flashes tuning method\n",
    "diff = []\n",
    "for i in range(len(y)-1):\n",
    "    diff.append(1 if abs(y[i] - y[i+1]) > 200 else 0) # TODO: figure out tuning metrics\n",
    "diff.append(0) # adjust shape for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f97fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectUnsafeFlashesFrame(intensity, fps, max_flashes=3):\n",
    "    warning_count = 0\n",
    "    count = 0\n",
    "    ## added count to show all flashes within the video in a 5 frame range\n",
    "    for i in range(len(intensity) - fps):\n",
    "        num_flash = np.sum(intensity[i:i+fps])\n",
    "        if(num_flash > max_flashes and count == 0):\n",
    "            print(f\"{num_flash} flashes detected at seconds: {math.ceil(i/30)+1}\")\n",
    "            warning_count = warning_count + 1                \n",
    "        count = count + 1\n",
    "        if(count >= fps) : count = 0        \n",
    "    return warning_count, i\n",
    "\n",
    "detectUnsafeFlashesFrame(diff, int(metadata['fps']), max_flashes=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
